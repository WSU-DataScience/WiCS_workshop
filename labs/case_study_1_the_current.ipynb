{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case Study - The Current\n",
    "\n",
    "* The Current is an alternative radio station\n",
    "* We will pull information about the play list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\">Exercise - Go the the following page and inspect the following </font>\n",
    "\n",
    "* Song title\n",
    "* Artist\n",
    "* Play time\n",
    "* Day, date, period (am/pm)\n",
    "\n",
    "http://www.thecurrent.org/playlist/2014-01-01/01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "example_url = 'http://www.thecurrent.org/playlist/2014-01-01/01'\n",
    "s = requests.Session()\n",
    "r = s.get(example_url)\n",
    "\n",
    "soup = bs4.BeautifulSoup(r.content, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pull off the period of the day (am/pm)\n",
    "\n",
    "Pull out the \"am\"/\"pm\"\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Search the soup\n",
    "    1. There should be one item returned\n",
    "4. Use soup\\string methods to pull out the info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"hour-header open\">\n",
       "      1:00 am to  2:00 am\n",
       "   </span>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I should have used find here...Why?\n",
    "soup('span', class_=\"hour-header open\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(soup('span', class_=\"hour-header open\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<span class=\"hour-header open\">\n",
       "     1:00 am to  2:00 am\n",
       "  </span>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup('span', class_=\"hour-header open\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n     1:00 am to  2:00 am\\n  '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup('span', class_=\"hour-header open\")[0].next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n     1:00 am ', '  2:00 am\\n  ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup('span', class_=\"hour-header open\")[0].next.split('to')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n     1:00 am '"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup('span', class_=\"hour-header open\")[0].next.split('to')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n     1:00 am'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup('span', class_=\"hour-header open\")[0].next.split('to')[0].rstrip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'am'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "period = soup('span', class_=\"hour-header open\")[0].next.split('to')[0].rstrip()[-2:]\n",
    "period"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Breakout activity </font>\n",
    "\n",
    "* Pull out the day of the week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Title of each song\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Use `soup.findAll` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Use soup/string methods to pull out the title\n",
    "6. Use a list comprehension to process all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h5 class=\"title\">Holy Roller\n",
       "         <h5 class=\"artist\">Thao and The Get Down Stay Down\n",
       "       </h5></h5>, <h5 class=\"title\">Kingdom of Rust\n",
       "         <h5 class=\"artist\">Doves\n",
       "       </h5></h5>, <h5 class=\"title\">Black Dog\n",
       "         <h5 class=\"artist\">Frankie Lee\n",
       "       </h5></h5>, <h5 class=\"title\">Turn It Around\n",
       "         <h5 class=\"artist\">Lucius\n",
       "       </h5></h5>, <h5 class=\"title\">Flavor of the Month\n",
       "         <h5 class=\"artist\">The Posies\n",
       "       </h5></h5>, <h5 class=\"title\">Potential Wife\n",
       "         <h5 class=\"artist\">Strange Names\n",
       "       </h5></h5>, <h5 class=\"title\">24 Hours\n",
       "         <h5 class=\"artist\">Sky Ferreira\n",
       "       </h5></h5>, <h5 class=\"title\">Who's Gonna Shoe Your Pretty Little Feet?\n",
       "         <h5 class=\"artist\">Billie Joe and Norah\n",
       "       </h5></h5>, <h5 class=\"title\">Marigold\n",
       "         <h5 class=\"artist\">J. Roddy Walston and The Business\n",
       "       </h5></h5>, <h5 class=\"title\">High Road\n",
       "         <h5 class=\"artist\">Cults\n",
       "       </h5></h5>, <h5 class=\"title\">The Vampyre Of Time and Memory\n",
       "         <h5 class=\"artist\">Queens of the Stone Age\n",
       "       </h5></h5>, <h5 class=\"title\">Valerie Plame\n",
       "         <h5 class=\"artist\">The Decemberists\n",
       "       </h5></h5>, <h5 class=\"title\">Morning Song\n",
       "         <h5 class=\"artist\">The Avett Brothers\n",
       "       </h5></h5>, <h5 class=\"title\">(You Will) Set The World On Fire\n",
       "         <h5 class=\"artist\">David Bowie\n",
       "       </h5></h5>, <h5 class=\"title\">Sixteen Saltines\n",
       "         <h5 class=\"artist\">Jack White\n",
       "       </h5></h5>, <h5 class=\"title\">Wave of Mutilation\n",
       "         <h5 class=\"artist\">Pixies\n",
       "       </h5></h5>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.findAll('h5', class_ = \"title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<h5 class=\"title\">Holy Roller\n",
       "        <h5 class=\"artist\">Thao and The Get Down Stay Down\n",
       "      </h5></h5>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tag =  soup.findAll('h5', class_ = \"title\")[0]\n",
    "example_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Holy Roller\\n        '"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tag.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Holy Roller'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_tag.next.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Holy Roller',\n",
       " 'Kingdom of Rust',\n",
       " 'Black Dog',\n",
       " 'Turn It Around',\n",
       " 'Flavor of the Month',\n",
       " 'Potential Wife',\n",
       " '24 Hours',\n",
       " \"Who's Gonna Shoe Your Pretty Little Feet?\",\n",
       " 'Marigold',\n",
       " 'High Road',\n",
       " 'The Vampyre Of Time and Memory',\n",
       " 'Valerie Plame',\n",
       " 'Morning Song',\n",
       " '(You Will) Set The World On Fire',\n",
       " 'Sixteen Saltines',\n",
       " 'Wave of Mutilation']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = [tag.next.strip() for tag in soup.findAll('h5', class_ = \"title\")]\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Break out session - Name of the Artist </font>\n",
    "\n",
    "1. Inspect the element\n",
    "2. Identify the html tag and class\n",
    "3. Use `soup.findAll` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Use soup/string methods to pull out the title\n",
    "6. Use a list comprehension to process all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"red\"> Break out session - song start time </font>\n",
    "\n",
    "1. Inspect the element\n",
    "    1. This one is tricky\n",
    "    2. Time tag does not have a tag, but\n",
    "    3. The surrounding div does have a class\n",
    "2. Identify the html tag and class\n",
    "3. Use `soup.findAll` to make a list of all relevant tags\n",
    "4. Pull off an example case\n",
    "5. Use soup/string methods to pull out the title\n",
    "6. Use a list comprehension to process all tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_period(soup):\n",
    "    search = soup('span', class_=\"hour-header open\")\n",
    "    if len(search) > 0:\n",
    "        return search[0].next.split('to')[0].rstrip()[-2:]\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def get_day(soup):\n",
    "    search = soup('a', class_=\"start-picker\")\n",
    "    if len(search) > 0:\n",
    "        return search[0].next.split(',')[0]\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "def get_song_info(url):\n",
    "    print(\"Starting {0} urls\".format(url))\n",
    "    date = url.split('/')[-2]\n",
    "    s = requests.Session()\n",
    "    r = s.get(url)\n",
    "    soup = bs4.BeautifulSoup(r.content, 'lxml')\n",
    "    period = get_period(soup)\n",
    "    day_of_week = get_day(soup)\n",
    "    soup = bs4.BeautifulSoup(r.content)\n",
    "    titles = [t.next.strip() for t in soup.findAll('h5', class_=\"title\")]\n",
    "    artists = [a.next.strip() for a in soup.findAll('h5',class_='artist')]\n",
    "    times = [d.time.next.strip() for d in soup('div', class_=\"two columns songTime\")]\n",
    "    song_info = [(day_of_week, date, time, period, title, artist) \n",
    "             for time, title, artist in zip(times, titles, artists)]\n",
    "    return song_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting http://www.thecurrent.org/playlist/2014-01-01/01 urls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bn8210wy/.pyenv/versions/anaconda3-4.1.1/lib/python3.5/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:59',\n",
       "  'am',\n",
       "  'Holy Roller',\n",
       "  'Thao and The Get Down Stay Down'),\n",
       " ('Wednesday', '2014-01-01', '1:54', 'am', 'Kingdom of Rust', 'Doves'),\n",
       " ('Wednesday', '2014-01-01', '1:51', 'am', 'Black Dog', 'Frankie Lee'),\n",
       " ('Wednesday', '2014-01-01', '1:46', 'am', 'Turn It Around', 'Lucius'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:44',\n",
       "  'am',\n",
       "  'Flavor of the Month',\n",
       "  'The Posies'),\n",
       " ('Wednesday', '2014-01-01', '1:38', 'am', 'Potential Wife', 'Strange Names'),\n",
       " ('Wednesday', '2014-01-01', '1:34', 'am', '24 Hours', 'Sky Ferreira'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:31',\n",
       "  'am',\n",
       "  \"Who's Gonna Shoe Your Pretty Little Feet?\",\n",
       "  'Billie Joe and Norah'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:27',\n",
       "  'am',\n",
       "  'Marigold',\n",
       "  'J. Roddy Walston and The Business'),\n",
       " ('Wednesday', '2014-01-01', '1:23', 'am', 'High Road', 'Cults'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:19',\n",
       "  'am',\n",
       "  'The Vampyre Of Time and Memory',\n",
       "  'Queens of the Stone Age'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:13',\n",
       "  'am',\n",
       "  'Valerie Plame',\n",
       "  'The Decemberists'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:09',\n",
       "  'am',\n",
       "  'Morning Song',\n",
       "  'The Avett Brothers'),\n",
       " ('Wednesday',\n",
       "  '2014-01-01',\n",
       "  '1:05',\n",
       "  'am',\n",
       "  '(You Will) Set The World On Fire',\n",
       "  'David Bowie'),\n",
       " ('Wednesday', '2014-01-01', '1:03', 'am', 'Sixteen Saltines', 'Jack White'),\n",
       " ('Wednesday', '2014-01-01', '1:01', 'am', 'Wave of Mutilation', 'Pixies')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_song_info(example_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collecting a years worth of data\n",
    "\n",
    "## Step 1 - Identify the url pattern\n",
    "\n",
    "The Current uses urls of the following pattern\n",
    "\n",
    "    'http://www.thecurrent.org/playlist/2017-05-04/10'\n",
    "\n",
    "or \n",
    "\n",
    "    'http://www.thecurrent.org/playlist/year-month-day/hour'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: How might you generate all combinations for a given year?\n",
    "\n",
    "**Answer:** Python has a tool for that!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#numdays = 365 HAHA JUST KIDDING!\n",
    "numdays = 5\n",
    "base = datetime.datetime.today()\n",
    "dts = [base - datetime.timedelta(hours = h) for h in range(0, numdays*24)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def output_address(dt):\n",
    "    fmt = 'http://www.thecurrent.org/playlist/%Y-%m-%d/%H'\n",
    "    return dt.strftime(fmt)\n",
    "\n",
    "def test_output_address():\n",
    "    date = datetime.datetime(2000,1,1,1)\n",
    "    assert output_address(date) == 'http://www.thecurrent.org/playlist/2000-01-01/01'\n",
    "test_output_address()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.thecurrent.org/playlist/2018-03-21/16',\n",
       " 'http://www.thecurrent.org/playlist/2018-03-21/15',\n",
       " 'http://www.thecurrent.org/playlist/2018-03-21/14',\n",
       " 'http://www.thecurrent.org/playlist/2018-03-21/13',\n",
       " 'http://www.thecurrent.org/playlist/2018-03-21/12',\n",
       " 'http://www.thecurrent.org/playlist/2018-03-21/11',\n",
       " 'http://www.thecurrent.org/playlist/2018-03-21/10',\n",
       " 'http://www.thecurrent.org/playlist/2018-03-21/09',\n",
       " 'http://www.thecurrent.org/playlist/2018-03-21/08',\n",
       " 'http://www.thecurrent.org/playlist/2018-03-21/07']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls = [output_address(d) for d in dts]\n",
    "urls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting http://www.thecurrent.org/playlist/2018-03-21/16 urls\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bn8210wy/.pyenv/versions/anaconda3-4.1.1/lib/python3.5/site-packages/bs4/__init__.py:166: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "To get rid of this warning, change this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 5 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/15 urls\n",
      "Processed 10 songs\n",
      "Processed 15 songs\n",
      "Processed 20 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/14 urls\n",
      "Processed 25 songs\n",
      "Processed 30 songs\n",
      "Processed 35 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/13 urls\n",
      "Processed 40 songs\n",
      "Processed 45 songs\n",
      "Processed 50 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/12 urls\n",
      "Processed 55 songs\n",
      "Processed 60 songs\n",
      "Processed 65 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/11 urls\n",
      "Processed 70 songs\n",
      "Processed 75 songs\n",
      "Processed 80 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/10 urls\n",
      "Processed 85 songs\n",
      "Processed 90 songs\n",
      "Processed 95 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/09 urls\n",
      "Processed 100 songs\n",
      "Processed 105 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/08 urls\n",
      "Processed 110 songs\n",
      "Processed 115 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/07 urls\n",
      "Processed 120 songs\n",
      "Processed 125 songs\n",
      "Processed 130 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/06 urls\n",
      "Processed 135 songs\n",
      "Processed 140 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/05 urls\n",
      "Processed 145 songs\n",
      "Processed 150 songs\n",
      "Processed 155 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/04 urls\n",
      "Processed 160 songs\n",
      "Processed 165 songs\n",
      "Processed 170 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/03 urls\n",
      "Processed 175 songs\n",
      "Processed 180 songs\n",
      "Processed 185 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/02 urls\n",
      "Processed 190 songs\n",
      "Processed 195 songs\n",
      "Processed 200 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/01 urls\n",
      "Processed 205 songs\n",
      "Processed 210 songs\n",
      "Processed 215 songs\n",
      "Processed 220 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-21/00 urls\n",
      "Processed 225 songs\n",
      "Processed 230 songs\n",
      "Processed 235 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/23 urls\n",
      "Processed 240 songs\n",
      "Processed 245 songs\n",
      "Processed 250 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/22 urls\n",
      "Processed 255 songs\n",
      "Processed 260 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/21 urls\n",
      "Processed 265 songs\n",
      "Processed 270 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/20 urls\n",
      "Processed 275 songs\n",
      "Processed 280 songs\n",
      "Processed 285 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/19 urls\n",
      "Processed 290 songs\n",
      "Processed 295 songs\n",
      "Processed 300 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/18 urls\n",
      "Processed 305 songs\n",
      "Processed 310 songs\n",
      "Processed 315 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/17 urls\n",
      "Processed 320 songs\n",
      "Processed 325 songs\n",
      "Processed 330 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/16 urls\n",
      "Processed 335 songs\n",
      "Processed 340 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/15 urls\n",
      "Processed 345 songs\n",
      "Processed 350 songs\n",
      "Processed 355 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/14 urls\n",
      "Processed 360 songs\n",
      "Processed 365 songs\n",
      "Processed 370 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/13 urls\n",
      "Processed 375 songs\n",
      "Processed 380 songs\n",
      "Processed 385 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/12 urls\n",
      "Processed 390 songs\n",
      "Processed 395 songs\n",
      "Processed 400 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/11 urls\n",
      "Processed 405 songs\n",
      "Processed 410 songs\n",
      "Processed 415 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/10 urls\n",
      "Processed 420 songs\n",
      "Processed 425 songs\n",
      "Processed 430 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/09 urls\n",
      "Processed 435 songs\n",
      "Processed 440 songs\n",
      "Processed 445 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/08 urls\n",
      "Processed 450 songs\n",
      "Processed 455 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/07 urls\n",
      "Processed 460 songs\n",
      "Processed 465 songs\n",
      "Processed 470 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/06 urls\n",
      "Processed 475 songs\n",
      "Processed 480 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/05 urls\n",
      "Processed 485 songs\n",
      "Processed 490 songs\n",
      "Processed 495 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/04 urls\n",
      "Processed 500 songs\n",
      "Processed 505 songs\n",
      "Processed 510 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/03 urls\n",
      "Processed 515 songs\n",
      "Processed 520 songs\n",
      "Processed 525 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/02 urls\n",
      "Processed 530 songs\n",
      "Processed 535 songs\n",
      "Processed 540 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/01 urls\n",
      "Processed 545 songs\n",
      "Processed 550 songs\n",
      "Processed 555 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-20/00 urls\n",
      "Processed 560 songs\n",
      "Processed 565 songs\n",
      "Processed 570 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/23 urls\n",
      "Processed 575 songs\n",
      "Processed 580 songs\n",
      "Processed 585 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/22 urls\n",
      "Processed 590 songs\n",
      "Processed 595 songs\n",
      "Processed 600 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/21 urls\n",
      "Processed 605 songs\n",
      "Processed 610 songs\n",
      "Processed 615 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/20 urls\n",
      "Processed 620 songs\n",
      "Processed 625 songs\n",
      "Processed 630 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/19 urls\n",
      "Processed 635 songs\n",
      "Processed 640 songs\n",
      "Processed 645 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/18 urls\n",
      "Processed 650 songs\n",
      "Processed 655 songs\n",
      "Processed 660 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/17 urls\n",
      "Processed 665 songs\n",
      "Processed 670 songs\n",
      "Processed 675 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/16 urls\n",
      "Processed 680 songs\n",
      "Processed 685 songs\n",
      "Processed 690 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/15 urls\n",
      "Processed 695 songs\n",
      "Processed 700 songs\n",
      "Processed 705 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/14 urls\n",
      "Processed 710 songs\n",
      "Processed 715 songs\n",
      "Processed 720 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/13 urls\n",
      "Processed 725 songs\n",
      "Processed 730 songs\n",
      "Processed 735 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/12 urls\n",
      "Processed 740 songs\n",
      "Processed 745 songs\n",
      "Processed 750 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/11 urls\n",
      "Processed 755 songs\n",
      "Processed 760 songs\n",
      "Processed 765 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/10 urls\n",
      "Processed 770 songs\n",
      "Processed 775 songs\n",
      "Processed 780 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/09 urls\n",
      "Processed 785 songs\n",
      "Processed 790 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/08 urls\n",
      "Processed 795 songs\n",
      "Processed 800 songs\n",
      "Processed 805 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/07 urls\n",
      "Processed 810 songs\n",
      "Processed 815 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/06 urls\n",
      "Processed 820 songs\n",
      "Processed 825 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/05 urls\n",
      "Processed 830 songs\n",
      "Processed 835 songs\n",
      "Processed 840 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/04 urls\n",
      "Processed 845 songs\n",
      "Processed 850 songs\n",
      "Processed 855 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/03 urls\n",
      "Processed 860 songs\n",
      "Processed 865 songs\n",
      "Processed 870 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/02 urls\n",
      "Processed 875 songs\n",
      "Processed 880 songs\n",
      "Processed 885 songs\n",
      "Processed 890 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/01 urls\n",
      "Processed 895 songs\n",
      "Processed 900 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-19/00 urls\n",
      "Processed 905 songs\n",
      "Processed 910 songs\n",
      "Processed 915 songs\n",
      "Processed 920 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/23 urls\n",
      "Processed 925 songs\n",
      "Processed 930 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/22 urls\n",
      "Processed 935 songs\n",
      "Processed 940 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/21 urls\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/20 urls\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/19 urls\n",
      "Processed 945 songs\n",
      "Processed 950 songs\n",
      "Processed 955 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/18 urls\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed 960 songs\n",
      "Processed 965 songs\n",
      "Processed 970 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/17 urls\n",
      "Processed 975 songs\n",
      "Processed 980 songs\n",
      "Processed 985 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/16 urls\n",
      "Processed 990 songs\n",
      "Processed 995 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/15 urls\n",
      "Processed 1000 songs\n",
      "Flushing output\n",
      "Processed 1005 songs\n",
      "Processed 1010 songs\n",
      "Processed 1015 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/14 urls\n",
      "Processed 1020 songs\n",
      "Processed 1025 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/13 urls\n",
      "Processed 1030 songs\n",
      "Processed 1035 songs\n",
      "Processed 1040 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/12 urls\n",
      "Processed 1045 songs\n",
      "Processed 1050 songs\n",
      "Processed 1055 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/11 urls\n",
      "Processed 1060 songs\n",
      "Processed 1065 songs\n",
      "Processed 1070 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/10 urls\n",
      "Processed 1075 songs\n",
      "Processed 1080 songs\n",
      "Processed 1085 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/09 urls\n",
      "Processed 1090 songs\n",
      "Processed 1095 songs\n",
      "Processed 1100 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/08 urls\n",
      "Processed 1105 songs\n",
      "Processed 1110 songs\n",
      "Processed 1115 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/07 urls\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/06 urls\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/05 urls\n",
      "Processed 1120 songs\n",
      "Processed 1125 songs\n",
      "Processed 1130 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/04 urls\n",
      "Processed 1135 songs\n",
      "Processed 1140 songs\n",
      "Processed 1145 songs\n",
      "Processed 1150 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/03 urls\n",
      "Processed 1155 songs\n",
      "Processed 1160 songs\n",
      "Processed 1165 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/02 urls\n",
      "Processed 1170 songs\n",
      "Processed 1175 songs\n",
      "Processed 1180 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/01 urls\n",
      "Processed 1185 songs\n",
      "Processed 1190 songs\n",
      "Processed 1195 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-18/00 urls\n",
      "Processed 1200 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/23 urls\n",
      "Processed 1205 songs\n",
      "Processed 1210 songs\n",
      "Processed 1215 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/22 urls\n",
      "Processed 1220 songs\n",
      "Processed 1225 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/21 urls\n",
      "Processed 1230 songs\n",
      "Processed 1235 songs\n",
      "Processed 1240 songs\n",
      "Processed 1245 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/20 urls\n",
      "Processed 1250 songs\n",
      "Processed 1255 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/19 urls\n",
      "Processed 1260 songs\n",
      "Processed 1265 songs\n",
      "Processed 1270 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/18 urls\n",
      "Processed 1275 songs\n",
      "Processed 1280 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/17 urls\n",
      "Processed 1285 songs\n",
      "Processed 1290 songs\n",
      "Processed 1295 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/16 urls\n",
      "Processed 1300 songs\n",
      "Processed 1305 songs\n",
      "Processed 1310 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/15 urls\n",
      "Processed 1315 songs\n",
      "Processed 1320 songs\n",
      "Processed 1325 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/14 urls\n",
      "Processed 1330 songs\n",
      "Processed 1335 songs\n",
      "Processed 1340 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/13 urls\n",
      "Processed 1345 songs\n",
      "Processed 1350 songs\n",
      "Processed 1355 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/12 urls\n",
      "Processed 1360 songs\n",
      "Processed 1365 songs\n",
      "Processed 1370 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/11 urls\n",
      "Processed 1375 songs\n",
      "Processed 1380 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/10 urls\n",
      "Processed 1385 songs\n",
      "Processed 1390 songs\n",
      "Processed 1395 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/09 urls\n",
      "Processed 1400 songs\n",
      "Processed 1405 songs\n",
      "Processed 1410 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/08 urls\n",
      "Processed 1415 songs\n",
      "Processed 1420 songs\n",
      "Processed 1425 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/07 urls\n",
      "Processed 1430 songs\n",
      "Processed 1435 songs\n",
      "Processed 1440 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/06 urls\n",
      "Processed 1445 songs\n",
      "Processed 1450 songs\n",
      "Processed 1455 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/05 urls\n",
      "Processed 1460 songs\n",
      "Processed 1465 songs\n",
      "Processed 1470 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/04 urls\n",
      "Processed 1475 songs\n",
      "Processed 1480 songs\n",
      "Processed 1485 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/03 urls\n",
      "Processed 1490 songs\n",
      "Processed 1495 songs\n",
      "Processed 1500 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/02 urls\n",
      "Processed 1505 songs\n",
      "Processed 1510 songs\n",
      "Processed 1515 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/01 urls\n",
      "Processed 1520 songs\n",
      "Processed 1525 songs\n",
      "Processed 1530 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-17/00 urls\n",
      "Processed 1535 songs\n",
      "Processed 1540 songs\n",
      "Processed 1545 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-16/23 urls\n",
      "Processed 1550 songs\n",
      "Processed 1555 songs\n",
      "Processed 1560 songs\n",
      "Processed 1565 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-16/22 urls\n",
      "Processed 1570 songs\n",
      "Processed 1575 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-16/21 urls\n",
      "Processed 1580 songs\n",
      "Processed 1585 songs\n",
      "Processed 1590 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-16/20 urls\n",
      "Processed 1595 songs\n",
      "Processed 1600 songs\n",
      "Processed 1605 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-16/19 urls\n",
      "Processed 1610 songs\n",
      "Processed 1615 songs\n",
      "Processed 1620 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-16/18 urls\n",
      "Processed 1625 songs\n",
      "Processed 1630 songs\n",
      "Processed 1635 songs\n",
      "Starting http://www.thecurrent.org/playlist/2018-03-16/17 urls\n",
      "Processed 1640 songs\n",
      "Processed 1645 songs\n"
     ]
    }
   ],
   "source": [
    "with open('the_current_last_year_new.csv', 'w') as outfile:\n",
    "    header = \"Weekday,Date,Time,Period,Song_Title,Artist\"\n",
    "    print(header, file=outfile)\n",
    "    count = 0\n",
    "    for url in urls:\n",
    "        for song_info in get_song_info(url):\n",
    "            count += 1\n",
    "            if count % 5 == 0:\n",
    "                print(\"Processed {0} songs\".format(count))\n",
    "            join_info = \",\".join(song_info)\n",
    "            print(join_info, file=outfile)\n",
    "            if count % 1000 == 0:\n",
    "                print(\"Flushing output\")\n",
    "                outfile.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
